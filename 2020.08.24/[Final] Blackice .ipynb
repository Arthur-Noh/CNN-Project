{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "     # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu,True)\n",
    "        logical_gpus=tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus),\"Physical GPUs,\",len(logical_gpus),\"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        #Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'C:/Users/Arthur_Noh/Desktop/dataset/Train'\n",
    "TEST_DIR = 'C:/Users/Arthur_Noh/Desktop/dataset/Test'\n",
    "\n",
    "CATEGORIES = ['blackice','road','snow','wet']\n",
    "\n",
    "IMG_SIZE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_test = []\n",
    "Y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackice 의 파일 길이 :  10000\n",
      "blackice : b_1.jpg\n",
      "blackice : b_2799.jpg\n",
      "blackice : b_4599.jpg\n",
      "blackice : b_6399.jpg\n",
      "blackice : b_8199.jpg\n",
      "\n",
      "\n",
      "road 의 파일 길이 :  10000\n",
      "road : r_1.jpg\n",
      "road : r_2799.jpg\n",
      "road : r_4599.jpg\n",
      "road : r_6399.jpg\n",
      "road : r_8199.jpg\n",
      "\n",
      "\n",
      "snow 의 파일 길이 :  10000\n",
      "snow : s_1.jpg\n",
      "snow : s_2799.jpg\n",
      "snow : s_4599.jpg\n",
      "snow : s_6399.jpg\n",
      "snow : s_8199.jpg\n",
      "\n",
      "\n",
      "wet 의 파일 길이 :  10000\n",
      "wet : w_1.jpg\n",
      "wet : w_2799.jpg\n",
      "wet : w_4599.jpg\n",
      "wet : w_6399.jpg\n",
      "wet : w_8199.jpg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "for idx, category in enumerate(CATEGORIES):\n",
    "    # one-hot incoding\n",
    "    label = [0 for i in range(len(CATEGORIES))]\n",
    "    label[idx] = 1\n",
    "    \n",
    "    path = os.path.join(TRAIN_DIR, category)\n",
    "    # check to see if read images work\n",
    "    print(category, '의 파일 길이 : ', len(os.listdir(path)))\n",
    "    \n",
    "    for i, image in enumerate(os.listdir(path)):\n",
    "        img = cv2.imread(os.path.join(path, image),\n",
    "                        cv2.IMREAD_GRAYSCALE)        \n",
    "        # Make image size that we want\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        data = np.array(img)\n",
    "        \n",
    "        # input data in temp variable\n",
    "        X_train.append(data)\n",
    "        Y_train.append(label)\n",
    "        \n",
    "        # check image lists\n",
    "        if i % 2000 == 0:\n",
    "            print(category, ':', image)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackice 의 파일 길이 :  1000\n",
      "blackice : b_2901.jpg\n",
      "blackice : b_3101.jpg\n",
      "blackice : b_3301.jpg\n",
      "blackice : b_3501.jpg\n",
      "blackice : b_3701.jpg\n",
      "\n",
      "\n",
      "road 의 파일 길이 :  1000\n",
      "road : r_3901.jpg\n",
      "road : r_4101.jpg\n",
      "road : r_4301.jpg\n",
      "road : r_4501.jpg\n",
      "road : r_4701.jpg\n",
      "\n",
      "\n",
      "snow 의 파일 길이 :  1000\n",
      "snow : s_2901.jpg\n",
      "snow : s_3101.jpg\n",
      "snow : s_3301.jpg\n",
      "snow : s_3501.jpg\n",
      "snow : s_3701.jpg\n",
      "\n",
      "\n",
      "wet 의 파일 길이 :  1000\n",
      "wet : w_3901.jpg\n",
      "wet : w_4101.jpg\n",
      "wet : w_4301.jpg\n",
      "wet : w_4501.jpg\n",
      "wet : w_4701.jpg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing data\n",
    "for idx, category in enumerate(CATEGORIES):\n",
    "    # one-hot incoding\n",
    "    label = [0 for i in range(len(CATEGORIES))]\n",
    "    label[idx] = 1\n",
    "    \n",
    "    path = os.path.join(TEST_DIR, category)\n",
    "    # check to see if read images work\n",
    "    print(category, '의 파일 길이 : ', len(os.listdir(path)))\n",
    "    \n",
    "    for i, image in enumerate(os.listdir(path)):\n",
    "        img = cv2.imread(os.path.join(path, image),\n",
    "                        cv2.IMREAD_GRAYSCALE)        \n",
    "        # Make image size that we want\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        data = np.array(img)\n",
    "        \n",
    "        # input data in temp variable\n",
    "        X_test.append(data)\n",
    "        Y_test.append(label)\n",
    "        \n",
    "        # check image lists\n",
    "        if i % 200 == 0:\n",
    "            print(category, ':', image)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 150, 150, 1) (40000, 4)\n",
      "(4000, 150, 150, 1) (4000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 16)      160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 2,689,156\n",
      "Trainable params: 2,689,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(150,150,1), kernel_size=(3,3), filters=16, padding='same',activation='relu'),\n",
    "    tf.keras.layers.Conv2D(input_shape=(150,150,1), kernel_size=(3,3), filters=32, padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=256, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=256, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=4, activation='softmax')\n",
    "])\n",
    "# sparse 빼도됨\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3),\n",
    "                padding='same', input_shape=(150, 150, 1),\n",
    "                activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3),\n",
    "                padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),\n",
    "                padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3),\n",
    "                padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3),\n",
    "                padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3),\n",
    "                padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 150, 150, 16)      160       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 150, 150, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 9, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 2,689,156\n",
      "Trainable params: 2,689,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 51.5001 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0220s). Check your callbacks.\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.0082 - accuracy: 0.6406WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 1.0082 - accuracy: 0.6406 - val_loss: 1.6917 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.6490 - accuracy: 0.7270 - val_loss: 1.5193 - val_accuracy: 0.2705\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.5671 - accuracy: 0.7770 - val_loss: 1.9620 - val_accuracy: 0.0626\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.4775 - accuracy: 0.8270 - val_loss: 1.8576 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.4483 - accuracy: 0.8369 - val_loss: 1.7750 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.4043 - accuracy: 0.8537 - val_loss: 2.3861 - val_accuracy: 0.1215\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3981 - accuracy: 0.8563 - val_loss: 1.9269 - val_accuracy: 0.3904\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3808 - accuracy: 0.8661 - val_loss: 1.7053 - val_accuracy: 0.1114\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3642 - accuracy: 0.8698 - val_loss: 1.9327 - val_accuracy: 1.2500e-04\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3595 - accuracy: 0.8748 - val_loss: 1.7403 - val_accuracy: 0.0696\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3636 - accuracy: 0.8737 - val_loss: 1.4976 - val_accuracy: 0.0310\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3529 - accuracy: 0.8773 - val_loss: 1.5389 - val_accuracy: 0.1406\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3406 - accuracy: 0.8817 - val_loss: 1.8614 - val_accuracy: 0.0168\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3565 - accuracy: 0.8781 - val_loss: 1.9035 - val_accuracy: 0.0455\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3409 - accuracy: 0.8850 - val_loss: 1.8769 - val_accuracy: 0.0358\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3373 - accuracy: 0.8838 - val_loss: 2.1513 - val_accuracy: 0.0144\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3419 - accuracy: 0.8814 - val_loss: 1.9004 - val_accuracy: 0.0039\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3356 - accuracy: 0.8861 - val_loss: 1.6682 - val_accuracy: 0.1189\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3436 - accuracy: 0.8832 - val_loss: 2.4207 - val_accuracy: 0.0266\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3280 - accuracy: 0.8876 - val_loss: 1.9007 - val_accuracy: 0.0446\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.3420 - accuracy: 0.8819 - val_loss: 1.6552 - val_accuracy: 0.1524\n",
      "Epoch 22/100\n",
      " 889/1000 [=========================>....] - ETA: 2s - loss: 0.3410 - accuracy: 0.8820"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping=EarlyStopping(monitor='val_loss', mode='min', min_delta=1e-3, patience=20, verbose=1) \n",
    "history=model.fit(X_train, Y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyploy as plt\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
